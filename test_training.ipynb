{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Run model training and validates performances on the validation data**\n",
    "### **Author:** Alessandro Ulivi (ale.ulivi@gmail.com)\n",
    "### **Start day (yyyy/mm/dd):** 2024/10/18\n",
    "### **Description**\n",
    "#### The notebook:\n",
    "#### - loads train and validation data from the pip2_segmentation dataset (refer to README.txt).\n",
    "#### - Sets up and applies augmentation transformations.\n",
    "#### - Sets up the hyperparameters used to define and train the UNet model.\n",
    "#### - Trains the model on the (augmented) train data while validating training performances on the validation data.\n",
    "#### - While training, saves checkpoints.\n",
    "#### - While training, logs in TensorBoard: the training loss function, the validation loss function and metric, input and output images for the train and validation data.\n",
    "#### - Logs in TensorBoard the hypeparameters used for training.\n",
    "\n",
    "### **Requirements**\n",
    "#### The notebook runs on the pip2_segmentation environment and using the scripts of the pip2_segmentation project. Refer to https://github.com/AlessandroUlivi/pip2_segmentation.\n",
    "#### In addition, a \"runs\" folder and a \"checkpoints\" folder are expected to store, respectively, TensorBoards summaries of individual runs, and checkpoints of model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tensorboard extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import RandomSampler, DataLoader, Subset\n",
    "from dataprep.data_preparation import make_dataset, compose, random_flip, random_translation, random_gaussian_or_uniform_noise, add_channel, normalize, to_tensor\n",
    "from utils import dict2mdtable\n",
    "from unet import UNet\n",
    "from train_model import run_training, run_training_no_val\n",
    "from metrics.metric import DiceCoefficient, DiceLoss, DiceBCELoss, FocalLoss, BCE_EdgeDiceLoss\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_data_dir = r\"C:\\Users\\aless\\OneDrive\\Desktop\\Ale\\personal\\projects\\pip2_segmentation\\data\\train\\raw\"\n",
    "train_label_data_dir = r\"C:\\Users\\aless\\OneDrive\\Desktop\\Ale\\personal\\projects\\pip2_segmentation\\data\\train\\label\"\n",
    "val_input_data_dir = r\"C:\\Users\\aless\\OneDrive\\Desktop\\Ale\\personal\\projects\\pip2_segmentation\\data\\validation\\raw\"\n",
    "val_label_data_dir = r\"C:\\Users\\aless\\OneDrive\\Desktop\\Ale\\personal\\projects\\pip2_segmentation\\data\\validation\\label\"\n",
    "test_input_data_dir = r\"C:\\Users\\aless\\OneDrive\\Desktop\\Ale\\personal\\projects\\pip2_segmentation\\data\\test\\raw\"\n",
    "test_label_data_dir = r\"C:\\Users\\aless\\OneDrive\\Desktop\\Ale\\personal\\projects\\pip2_segmentation\\data\\test\\label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate trasformations\n",
    "train_data_transformations_w_augmentation = [random_flip, random_translation, random_gaussian_or_uniform_noise, add_channel, to_tensor]\n",
    "train_trafos = partial(compose, transforms=train_data_transformations_w_augmentation)\n",
    "\n",
    "val_data_transformations = [add_channel, to_tensor] #NOTE: Data are not normalized as the normalization had been done at the moment of dataset creation and before chuking the images\n",
    "val_trafos = partial(compose, transforms=val_data_transformations)\n",
    "\n",
    "#create the train and validation datasets\n",
    "train_dataset = make_dataset(train_input_data_dir, train_label_data_dir, transform=train_trafos, shuffle_data=True, stack_axis=0)\n",
    "val_dataset = make_dataset(val_input_data_dir, val_label_data_dir, transform=val_trafos, shuffle_data=True, stack_axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 31768), started 1:31:08 ago. (Use '!kill 31768' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-661da15e5638b998\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-661da15e5638b998\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# open tensorboard inside of our notebook\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========\n",
    "# # pass data to DataLoader\n",
    "batch_size = 4\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "#only work on a small subset of the data, for the moment\n",
    "num_train_samples = 12\n",
    "train_sample_ds = Subset(train_dataset, np.arange(num_train_samples))\n",
    "train_sample_sampler = RandomSampler(train_sample_ds)\n",
    "train_loader = DataLoader(train_sample_ds, sampler=train_sample_sampler, batch_size=batch_size)\n",
    "\n",
    "num_val_samples = 12\n",
    "val_sample_ds = Subset(val_dataset, np.arange(num_val_samples))\n",
    "val_sample_sampler = RandomSampler(val_sample_ds)\n",
    "val_loader = DataLoader(val_sample_ds, sampler=val_sample_sampler, batch_size=batch_size)\n",
    "\n",
    "#=========\n",
    "# pass to device\n",
    "# if torch.cuda.is_available:\n",
    "#     print(\"using gpu\")\n",
    "#     device = torch.device(\"cuda\")\n",
    "# else:\n",
    "#     print(\"using cpu\")\n",
    "#     device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "#=========\n",
    "# set model's parameters\n",
    "final_activation=\"Sigmoid\"\n",
    "depth = 4\n",
    "num_fmaps = 64\n",
    "fmap_inc_factor = 4\n",
    "downsample_factor = 2\n",
    "kernel_size = 5\n",
    "padding = \"same\"\n",
    "upsample_mode = \"nearest\"\n",
    "unet_model = UNet(depth=depth,\n",
    "                  in_channels=1,\n",
    "                  out_channels=1,\n",
    "                  final_activation=final_activation,\n",
    "                  num_fmaps=num_fmaps,\n",
    "                  fmap_inc_factor=fmap_inc_factor,\n",
    "                  downsample_factor=downsample_factor,\n",
    "                  kernel_size=kernel_size,\n",
    "                  padding=padding,\n",
    "                  upsample_mode=upsample_mode).to(device)\n",
    "\n",
    "#=========\n",
    "# set loss function\n",
    "# loss_function = nn.BCELoss() #second place for the BCELoss - for the moment it seems that it does not manage to get values increasing... they remain low and the Sigmoids then fails\n",
    "# loss_function = DiceLoss() #Works for the very initial training but then quick leads to large \"positive pixels\" structures\n",
    "# loss_function = DiceBCELoss() #for the moment it seems that this is the best\n",
    "loss_function = BCE_EdgeDiceLoss()\n",
    "bce_weight = 1\n",
    "dice_weight = 1\n",
    "#it might be worthed to test FocalLoss (https://arxiv.org/pdf/1708.02002, https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch)\n",
    "\n",
    "#=========\n",
    "# set optimizer\n",
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam(unet_model.parameters(), lr=lr)\n",
    "\n",
    "#=========\n",
    "# set metrics\n",
    "bin_threshold=0.5\n",
    "metric = DiceCoefficient()\n",
    "\n",
    "#=========\n",
    "# indicate key\n",
    "# runs_counter = get_var_value(filename=\"varstore.dat\")\n",
    "my_key  = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# set logger's parameters\n",
    "logger = SummaryWriter(f\"runs/{my_key}\")\n",
    "log_interval=1\n",
    "log_image_interval=20\n",
    "\n",
    "\n",
    "#unrelated comment, could be useful to look into this https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/12 (0%)]\tLoss: 0.881349\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m lr_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfactor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m2\u001b[39m}\n\u001b[0;32m      6\u001b[0m checkpoint_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munet_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbce_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbce_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdice_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdice_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbin_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbin_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlog_image_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_image_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmy_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_save_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr_scheduler_flag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_scheduler_flag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbest_metric_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#=========\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#log all hyperparameters as text in Tensorboard\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#transform the kwards of the lr in a string\u001b[39;00m\n\u001b[0;32m     33\u001b[0m lr_kwargs_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aless\\OneDrive\\Desktop\\Ale\\personal\\projects\\pip2_segmentation\\code\\train_model.py:256\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m(model, optimizer, metric, n_epochs, train_loader, val_loader, loss_function, bin_threshold, bce_weight, dice_weight, logger, log_interval, log_image_interval, device, key, path, lr_scheduler_flag, lr_kwargs, x_dim, y_dim, best_metric_init)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# train for n_epochs. During the training inspect the predictions\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[1;32m--> 256\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m          \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m          \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbce_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbce_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdice_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdice_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m          \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m          \u001b[49m\u001b[43mlog_image_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_image_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m          \u001b[49m\u001b[43mtb_logger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m          \u001b[49m\u001b[43mx_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m          \u001b[49m\u001b[43my_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m          \u001b[49m\u001b[43mreturn_loss_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbin_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m#calculate the training step\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     step \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "File \u001b[1;32mc:\\Users\\aless\\OneDrive\\Desktop\\Ale\\personal\\projects\\pip2_segmentation\\code\\train_model.py:103\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, loader, optimizer, loss_function, epoch, bce_weight, dice_weight, log_interval, log_image_interval, tb_logger, device, x_dim, y_dim, return_loss_metric, metric, bin_threshold)\u001b[0m\n\u001b[0;32m    100\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# apply model and calculate the prediction\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m#crop y when prediction mask is smaller than label (padding is \"valid\")\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape:\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\envs\\pip2_segmentation\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\envs\\pip2_segmentation\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aless\\OneDrive\\Desktop\\Ale\\personal\\projects\\pip2_segmentation\\code\\unet.py:429\u001b[0m, in \u001b[0;36mUNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    427\u001b[0m concat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrop_and_concat(convolution_outputs[j], upsampled)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;66;03m#get the convolutional block corresponding at level j from the list of convolutional blocks assembled by the right_convs method. Pass the layer_input to it.\u001b[39;00m\n\u001b[1;32m--> 429\u001b[0m conv_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright_convs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m#update layer_input, so that the output of the convolutional block will be inputed to the upsampling operation of the next (higher) level\u001b[39;00m\n\u001b[0;32m    431\u001b[0m layer_input \u001b[38;5;241m=\u001b[39m conv_output\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\envs\\pip2_segmentation\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\envs\\pip2_segmentation\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aless\\OneDrive\\Desktop\\Ale\\personal\\projects\\pip2_segmentation\\code\\unet.py:65\u001b[0m, in \u001b[0;36mConvBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     62\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03m    applies the convolutional block to a 3D tensor (x, CYX) and returns the result.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\envs\\pip2_segmentation\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\envs\\pip2_segmentation\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\envs\\pip2_segmentation\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\envs\\pip2_segmentation\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\envs\\pip2_segmentation\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\envs\\pip2_segmentation\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\envs\\pip2_segmentation\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#=========\n",
    "# model's training with validation\n",
    "n_epochs = 2\n",
    "lr_scheduler_flag = True\n",
    "lr_kwargs={\"mode\":\"min\", \"factor\": 0.1, \"patience\":2}\n",
    "checkpoint_save_path = \"checkpoints\"\n",
    "run_training(model=unet_model,\n",
    "            optimizer=optimizer,\n",
    "            metric=metric, \n",
    "            n_epochs=n_epochs,\n",
    "            bce_weight=bce_weight,\n",
    "            dice_weight=dice_weight,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            loss_function=loss_function,\n",
    "            bin_threshold=bin_threshold,\n",
    "            logger=logger,\n",
    "            log_interval=log_interval,\n",
    "            log_image_interval=log_image_interval,\n",
    "            device=device,\n",
    "            key=my_key,\n",
    "            path=checkpoint_save_path,\n",
    "            lr_scheduler_flag=lr_scheduler_flag,\n",
    "            lr_kwargs=lr_kwargs,\n",
    "            x_dim=[-2,-1],\n",
    "            y_dim=[-2,-1],\n",
    "            best_metric_init=0)\n",
    "\n",
    "#=========\n",
    "#log all hyperparameters as text in Tensorboard\n",
    "\n",
    "#transform the kwards of the lr in a string\n",
    "lr_kwargs_str = \"\"\n",
    "for k in lr_kwargs:\n",
    "    lr_kwargs_str = lr_kwargs_str + f\"{k}:{lr_kwargs[k]},\"\n",
    "\n",
    "#form a dictionary to with all hyperparameters to be logged\n",
    "hparam_dict = {\"batch_size\":str(batch_size),\n",
    "                      \"final_activation\":final_activation,\n",
    "                      \"depth\":str(depth),\n",
    "                      \"num_fmaps\":str(num_fmaps),\n",
    "                      \"fmap_inc_factor\":str(fmap_inc_factor),\n",
    "                      \"downsample_factor\":str(downsample_factor),\n",
    "                      \"kernel_size\":str(kernel_size),\n",
    "                      \"padding\":padding,\n",
    "                      \"upsample_mode\":upsample_mode,\n",
    "                      \"loss_function\":str(loss_function),\n",
    "                      \"bce_weight\":str(bce_weight),\n",
    "                      \"dice_weight\":str(dice_weight),\n",
    "                      \"bin_threshold\":str(bin_threshold),\n",
    "                      \"optimizer\":str(optimizer),\n",
    "                      \"metric\":str(metric),\n",
    "                      \"n_epochs\":str(n_epochs),\n",
    "                      \"lr_scheduler_flag\":str(lr_scheduler_flag),\n",
    "                      \"lr_kwargs\":lr_kwargs_str}\n",
    "\n",
    "#transform the dictionary in a table-like string object\n",
    "hparam_table_like = dict2mdtable(hparam_dict, key='Name', val='Value', transform_2_string=False)\n",
    "\n",
    "#log the text in Tensorboard summary of the run\n",
    "logger.add_text('Hyperparams', hparam_table_like, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #=========\n",
    "# # model's training without validation\n",
    "# n_epochs = 8\n",
    "# lr_scheduler_flag = True\n",
    "# lr_kwargs={\"mode\":\"min\", \"factor\": 0.1, \"patience\":2}\n",
    "# checkpoint_save_path = \"checkpoints\"\n",
    "# run_training_no_val(model=unet_model,\n",
    "#                     optimizer=optimizer,\n",
    "#                     metric=metric,\n",
    "#                     n_epochs=n_epochs,\n",
    "#                     train_loader=train_loader,\n",
    "#                     loss_function=loss_function,\n",
    "#                     bin_threshold=bin_threshold,\n",
    "#                     logger=logger,\n",
    "#                     log_interval=log_interval,\n",
    "#                     log_image_interval=log_image_interval,\n",
    "#                     device=device,\n",
    "#                     key=my_key,\n",
    "#                     path=checkpoint_save_path,\n",
    "#                     lr_scheduler_flag = lr_scheduler_flag,\n",
    "#                     lr_kwargs=lr_kwargs,\n",
    "#                     x_dim=[-2,-1],\n",
    "#                     y_dim=[-2,-1],\n",
    "#                     best_metric_init = -1)\n",
    "\n",
    "# #=========\n",
    "# #log all hyperparameters as text in Tensorboard\n",
    "\n",
    "# #transform the kwards of the lr in a string\n",
    "# lr_kwargs_str = \"\"\n",
    "# for k in lr_kwargs:\n",
    "#     lr_kwargs_str = lr_kwargs_str + f\"{k}:{lr_kwargs[k]},\"\n",
    "\n",
    "# #form a dictionary to with all hyperparameters to be logged\n",
    "# hparam_dict = {\"batch_size\":str(batch_size),\n",
    "#                       \"final_activation\":final_activation,\n",
    "#                       \"depth\":str(depth),\n",
    "#                       \"num_fmaps\":str(num_fmaps),\n",
    "#                       \"fmap_inc_factor\":str(fmap_inc_factor),\n",
    "#                       \"downsample_factor\":str(downsample_factor),\n",
    "#                       \"kernel_size\":str(kernel_size),\n",
    "#                       \"padding\":padding,\n",
    "#                       \"upsample_mode\":upsample_mode,\n",
    "#                       \"loss_function\":str(loss_function),\n",
    "#                       \"bin_threshold\":str(bin_threshold),\n",
    "#                       \"optimizer\":str(optimizer),\n",
    "#                       \"metric\":str(metric),\n",
    "#                       \"n_epochs\":str(n_epochs),\n",
    "#                       \"lr_scheduler_flag\":str(lr_scheduler_flag),\n",
    "#                       \"lr_kwargs\":lr_kwargs_str}\n",
    "\n",
    "# #transform the dictionary in a table-like string object\n",
    "# hparam_table_like = dict2mdtable(hparam_dict, key='Name', val='Value', transform_2_string=False)\n",
    "\n",
    "# #log the text in Tensorboard summary of the run\n",
    "# logger.add_text('Hyperparams', hparam_table_like, 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip2_segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
