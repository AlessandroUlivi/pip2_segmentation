{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start date (yyyy/mm/dd): 2024/09/04\n",
    "Author: Alessandro Ulivi (ale.ulivi@gmail.com)\n",
    "Description: the notebook was written to split time-lapse files (each file is a 3D array with dimensions TYX) of pip2-enriched domain dynamics and corresponding manually annotated binary segmentation masks (each mask is a 3D array with dimensions TYX). The notebook:\n",
    "1) splits each individual time-lapse file and the corresponding segmentation mask into individual time-points (2D array of dimension YX obtained by splitting the intial time-lapse along the T axis).\n",
    "2) Individual time-points and corresponding segmentation mask are further chunked into arrays of 256x256 pixel size. When chunking, it is made sure that chunks for the same array don't overlap. 4 chunks are obtained per each individual time-point (4 chunks for the raw time-point and 4 for the corresponding segmentation mask). All together, these 4 chunks form a 512x512 array covering the central part of each time-point (raw time-point ad corresponding segmentation mask). The pixels at the boarder of the time-points, framing the 512x512 central chunked array, are discarded (the frame of discarded pixels has size 208 pixel at each top and bottom edge and 86 pixels at each left-right).\n",
    "3) chunks of individual time-points, both for the raw time-point and for the corresponding binary segmentation time-point, are saved only if the binary segmentation chunk contains some pixels which are labelled.\n",
    "4) When saving, the names of the raw chunks match the names of the corresponding chunks for the segmentaion mask. Raw time-points and segmentation masks are saved in separate folders. The structure of the saving name is \"{original name of the sample}_s{progressive numbering}_y{y coordinate of the pixel on the top left corner of the chunk within the original time-point array}_x{y coordinate of the pixel on the top left corner of the chunk within the original time-point array}.tif\"\n",
    "5) Data are divided in 3 fraction, each save in a different directory: a train fraction, a validation fraction and a test fraction.\n",
    "\n",
    "Expected structure of input and output folders.\n",
    "- input_folder\n",
    "    - input_raw_folder\n",
    "        - sample_1 -> raw time-lapse file. Dimensions TYX. The position of T dimension can vary. .tif file. The name contains the string target_structure. No other file in the sample_ folder contains the string\n",
    "        - sample_2 -> raw time-lapse file. Dimensions TYX. The position of T dimension can vary. .tif file. The name contains the string target_structure. No other file in the sample_ folder contains the string\n",
    "        ...\n",
    "    - input_masks_folder\n",
    "        - sample_1 -> manually labelled binary mask for the raw time-lapse file. Dimensions TYX. The position of T dimension can vary but it must match that of the corresponding raw time-lapse file. .tif file. The name contains the string target_structure. No other file in the sample_ folder contains the string\n",
    "        - sample_2 -> manually labelled binary mask for the raw time-lapse file. Dimensions TYX. The position of T dimension can vary but it must match that of the corresponding raw time-lapse file. .tif file. The name contains the string target_structure. No other file in the sample_ folder contains the string\n",
    "        ...\n",
    "\n",
    "- output_folder\n",
    "    - output_train_folder\n",
    "    - output_validation_folder\n",
    "    - output_test_test\n",
    "\n",
    "Input_folder, input_masks_folder, input_raw_folder, output_folder, output_train_folder, output_validation_folder, output_test_test can have any name. Their names are specified below.\n",
    "\n",
    "Otuput structure.\n",
    "- output_folder\n",
    "    - output_train_folder\n",
    "        - raw -> raw time-points. .tif file. Dimensions YX obtained by splittig raw time-lapse files along the Y axis. Time-lapse files from different sample_ folders are pooled.\n",
    "        - label -> manually labelled binary mask of individual time-points. .tif file. Dimensions YX obtained by splittig manually labelled binary masks along the Y axis. Masks from different sample_ folders are pooled.\n",
    "    - output_validation_folder\n",
    "        - raw -> raw time-points. .tif file. Dimensions YX obtained by splittig raw time-lapse files along the Y axis. Time-lapse files from different sample_ folders are pooled.\n",
    "        - label -> manually labelled binary mask of individual time-points. .tif file. Dimensions YX obtained by splittig manually labelled binary masks along the Y axis. Masks from different sample_ folders are pooled.\n",
    "    - output_test_test\n",
    "        - raw -> raw time-points. .tif file. Dimensions YX obtained by splittig raw time-lapse files along the Y axis. Time-lapse files from different sample_ folders are pooled.\n",
    "        - label -> manually labelled binary mask of individual time-points. .tif file. Dimensions YX obtained by splittig manually labelled binary masks along the Y axis. Masks from different sample_ folders are pooled.\n",
    "\n",
    "The subsets of files used as, respectively, the validation and test datasets are saved in, respectively the \"output_validation_folder\" and the \"output_test_test\" sub-folders of the output_folder.\n",
    "\n",
    "As files within \"sample_X\" folders are pooled in the output folders, the names of the raw time-lapse files and corresponding labelled binary masks are expected to be different between different \"sample_\" folders.\n",
    "\n",
    "NOTES:\n",
    "1) Time-lapse files have been obtained by imaging live at a Nikon CSU-X1 Spinning disk microscope the C. elegans early embryo (1-6 cells stage) using a 100x, 1.4NA, oil immersion objective (xy pixel size 0.11 um). The labelling of pip2-enriched domains is obtained using of the ACR074 C.elegans strain expressing mCherry fused with a PIP2 binding-domain.\n",
    "2) Raw time-lapse files in input_folder are not the actual raw images. They went through a pre-processing process involving the reorganization of the actual raw files into individual time-lapse files. During this reorganization matadata were lost.\n",
    "3) (note from 2024/09/04): the split between train, validation and test datasets is done, for the moment, by selecting, randomly, a certain number of samples (variables validation_fraction and test_fraction), and using them as validation and test datasets. An alternative method could have been to randomly select a fraction of time-points per each sample. However I fear that by doing this some data leaking might happen as time-points are not independent, in fact, a high correlation is expected (e.g. the emrbyo is usually positioned in the center of the field of view and does not move) and the closer the timepoints, the higher their correlation.\n",
    "4) (note from 2024/10/09): the chunking method leads to a potentia bias: because embryos are mostly centered in each time-point, by chunking a 512x512 array centered on the time-point into 4 non-overlapping chunks of 256x256 pixels, each chunk would have roughly half array of embryo and half array of background. For this reason labelled structures are mostly on the boarder of the chunk and not randomly distributed on the train arrays. This is an aspect which at the moment I am not considering, but might have to be considered in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import files\n",
    "import os\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import random\n",
    "from utils import listdirNHF, check_folder_files_else_make_folder, chunk_center, measure_labelled_pixels_fraction\n",
    "from data_preparation import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indicate the derectoris of the input folder and the output folder\n",
    "input_folder = r\"C:\\Users\\aless\\OneDrive\\Desktop\\Ale\\personal\\others\\courses_certificates\\EMBL_deeplearning_2024\\dataset\"\n",
    "output_folder = r\"C:\\Users\\aless\\OneDrive\\Desktop\\Ale\\personal\\projects\\pip2_segmentation\\data\"\n",
    "\n",
    "#Indicate folders names\n",
    "input_masks_folder_name = 'dl_training'\n",
    "input_raw_folder_name = 'raw'\n",
    "output_train_folder_name = 'train'\n",
    "output_validation_folder_name = 'validation'\n",
    "output_test_folder_name = 'test'\n",
    "\n",
    "#indicate the string of the target structure\n",
    "target_structure = \"pip2\"\n",
    "\n",
    "#indicate the axis along which to split files\n",
    "split_axis = 0\n",
    "\n",
    "#set the highpass threshold of labelled pixels to be present in the chunk of the image in order for it to be saved.\n",
    "#the threshold is a fraction. The chunk of the image (both raw and label mask) is saved if the fraction of labelled pixels in the image is > threshold_label_px\n",
    "threshold_label_px = 0.005 \n",
    "\n",
    "#indicate the fraction of data to be saved as validation dataset\n",
    "validation_fraction = 0.3\n",
    "\n",
    "#indicate the fraction of data to be saved as test dataset\n",
    "test_fraction = 0.2\n",
    "\n",
    "#indicate if a random.seed should be used when selecting the samples for training and test - by default a seed is used\n",
    "use_random_seed = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the directory of the input_mask_folder, the input_raw_folder, the output_train_folder, the output_validation_folder and the output_test_folder\n",
    "input_masks_folder = os.path.join(input_folder, input_masks_folder_name)\n",
    "input_raw_folder = os.path.join(input_folder, input_raw_folder_name)\n",
    "output_train_folder = os.path.join(output_folder, output_train_folder_name)\n",
    "output_validation_folder = os.path.join(output_folder, output_validation_folder_name)\n",
    "output_test_folder = os.path.join(output_folder, output_test_folder_name)\n",
    "\n",
    "#Initialize a variable to keep track of whether files have already been generated in the output folders\n",
    "files_presence_output = []\n",
    "\n",
    "#Create the \"raw\" and \"label\" sub-folders in output_train_folder, output_validation_folder and output_test_folder, if they don't exist\n",
    "# NOTE: track the fact that they have already been created or not and whether they contain or not files inside\n",
    "#--- train\n",
    "output_train_folder_raw = os.path.join(output_train_folder, 'raw')\n",
    "output_train_folder_raw_presence = check_folder_files_else_make_folder(output_train_folder_raw)\n",
    "files_presence_output.append(output_train_folder_raw_presence)\n",
    "\n",
    "output_train_folder_label = os.path.join(output_train_folder, 'label')\n",
    "output_train_folder_label_presence = check_folder_files_else_make_folder(output_train_folder_label)\n",
    "files_presence_output.append(output_train_folder_label_presence)\n",
    "\n",
    "#--- validation\n",
    "output_validation_folder_raw = os.path.join(output_validation_folder, 'raw')\n",
    "output_validation_folder_raw_presence = check_folder_files_else_make_folder(output_validation_folder_raw)\n",
    "files_presence_output.append(output_validation_folder_raw_presence)\n",
    "\n",
    "output_validation_folder_label = os.path.join(output_validation_folder, 'label')\n",
    "output_validation_folder_label_presence = check_folder_files_else_make_folder(output_validation_folder_label)\n",
    "files_presence_output.append(output_validation_folder_label_presence)\n",
    "\n",
    "#--- test\n",
    "output_test_folder_raw = os.path.join(output_test_folder, 'raw')\n",
    "output_test_folder_raw_presence = check_folder_files_else_make_folder(output_test_folder_raw)\n",
    "files_presence_output.append(output_test_folder_raw_presence)\n",
    "\n",
    "output_test_folder_label = os.path.join(output_test_folder, 'label')\n",
    "output_test_folder_label_presence = check_folder_files_else_make_folder(output_test_folder_label)\n",
    "files_presence_output.append(output_test_folder_label_presence)\n",
    "\n",
    "# if no file is already present in any of the raw, and label output folders.\n",
    "# split time-lapse files and the corresponding binary masks,\n",
    "# randomly assign the time-points to train, validation and test datasets\n",
    "# NOTE: avoiding the procedure if files have been created this is an extra precaution to avoid that the train and test datasets get mixed\n",
    "# when re-running or changing the code (e.g. as the split is done randomly and without seed, it is possible that a sample is assigned to train in a first run and\n",
    "# to test in a second run of the script).\n",
    "if any(files_presence_output):\n",
    "    print(\"WARNING! objects are found in some raw or label output folder. The processing is not continued. Eliminate any object present and re-run the script\")\n",
    "else:\n",
    "    #Create a list of files in input_masks_folder - note that these files correspond to the samples to analyse\n",
    "    input_masks_folder_samples_list = listdirNHF(input_masks_folder)\n",
    "\n",
    "    # if use_random_seed is set to True (default), used a random seed before splitting samples in train and test_samples\n",
    "    # else, split the train test datasets randomly\n",
    "    if use_random_seed:\n",
    "        #create the random seed\n",
    "        random.seed(33)\n",
    "        #randomly pick samples used for the test dataset\n",
    "        test_samples = random.sample(input_masks_folder_samples_list, k=round(test_fraction*len(input_masks_folder_samples_list)))\n",
    "        #remove the train samples from from the list of samples\n",
    "        train_validation_samples = [s for s in input_masks_folder_samples_list if s not in test_samples]\n",
    "        #randomly pick the samples used for the validation dataset - NOTE: the len() used in the k parameter is that of the sample list with ALL the samples\n",
    "        validation_samples = random.sample(train_validation_samples, k=round(validation_fraction*len(input_masks_folder_samples_list)))\n",
    "        #use the remaining samples for the train dataset\n",
    "        train_samples = [s1 for s1 in train_validation_samples if s1 not in validation_samples]\n",
    "\n",
    "    else:\n",
    "        #randomly pick samples used for the test dataset\n",
    "        test_samples = random.sample(input_masks_folder_samples_list, k=round(test_fraction*len(input_masks_folder_samples_list)))\n",
    "        #remove the train samples from from the list of samples\n",
    "        train_validation_samples = [s for s in input_masks_folder_samples_list if s not in test_samples]\n",
    "        #randomly pick the samples used for the validation dataset - NOTE: the len() used in the k parameter is that of the sample list with ALL the samples\n",
    "        validation_samples = random.sample(train_validation_samples, k=round(validation_fraction*len(input_masks_folder_samples_list)))\n",
    "        #use the remaining samples for the train dataset\n",
    "        train_samples = [s1 for s1 in train_validation_samples if s1 not in validation_samples]\n",
    "\n",
    "    #Iterate through the folders (samples) of the labelled masks in input_folder sub-directory input_masks_folder\n",
    "    for i_f in input_masks_folder_samples_list:\n",
    "        #create the directory of the folder containing labelled masks\n",
    "        label_mask_sample_folder_dir = os.path.join(input_masks_folder, i_f)\n",
    "        #get the directory of the raw data for the sample inside input_raw_folder\n",
    "        raw_sample_folder_dir = os.path.join(input_raw_folder, i_f)\n",
    "        #get the name of the file containing the target_structure string within the sample folder inside the raw data\n",
    "        target_raw_file = [r_f for r_f in listdirNHF(raw_sample_folder_dir) if target_structure in r_f][0] #note: 1 single file with the target name is expected\n",
    "        #get the radix of the saving file name\n",
    "        target_file_radix = f\"{target_raw_file[:target_raw_file.index(target_structure)+len(target_structure)]}_{i_f}\"\n",
    "        #get the directories of the files corresponding to the labelled mask in the corresponding raw data for the target structure\n",
    "        targstruct_labelled_mask_dir = os.path.join(label_mask_sample_folder_dir, [l_m for l_m in listdirNHF(label_mask_sample_folder_dir) if target_structure in l_m][0]) #note: 1 single file with the target name is expected\n",
    "        targstruct_raw_dir = os.path.join(raw_sample_folder_dir, target_raw_file)\n",
    "        #open the raw file and the labelled mask\n",
    "        targstruct_labelled_mask = tifffile.imread(targstruct_labelled_mask_dir)\n",
    "        targstruct_raw = tifffile.imread(targstruct_raw_dir)\n",
    "        #split targstruct_labelled_mask and targstruct_raw along split_axis\n",
    "        targstruct_labelled_mask = [np.squeeze(trg) for trg in np.split(targstruct_labelled_mask, indices_or_sections=targstruct_labelled_mask.shape[split_axis], axis=split_axis)]\n",
    "        targstruct_raw_split = [np.squeeze(trg1) for trg1 in np.split(targstruct_raw, indices_or_sections=targstruct_raw.shape[split_axis], axis=split_axis)]\n",
    "        #iterate through the splat arrays\n",
    "        for c_ount, split_array_raw in enumerate(targstruct_raw_split):\n",
    "            #get the label mask corresponding to the raw array\n",
    "            split_array_label = targstruct_labelled_mask[c_ount]\n",
    "            #divide split_array_raw and split_array_label into chunks\n",
    "            chunks_split_array_raw, coords_split_array_raw = chunk_center(split_array_raw, chunk_x=256,chunk_y=256)\n",
    "            chunks_split_array_label, coords_split_array_label = chunk_center(split_array_label, chunk_x=256,chunk_y=256)\n",
    "            #iterate through the chunks of chunks_split_array_label\n",
    "            for chk_n, chunk_array_label in enumerate(list(chunks_split_array_label)):\n",
    "                #calculate the fraction of labelled pixels in chunk_array_label\n",
    "                label_px_frac = measure_labelled_pixels_fraction(chunk_array_label)\n",
    "                #save the label chunk and the corresponding raw image in the respective train, validation or test folders if the fraction of label pixels\n",
    "                #is higher than threshold_label_px\n",
    "                if label_px_frac>threshold_label_px:\n",
    "                    #get the corresponding raw image chunk\n",
    "                    chunk_array_raw = chunks_split_array_raw[chk_n, ...]\n",
    "                    #get the coordinates of the top left pixel of the chunk, within the initial split_array_label\n",
    "                    chunk_y_coord, chunk_x_coord =  coords_split_array_label[chk_n][0],coords_split_array_label[chk_n][1] \n",
    "                    #form the radiz of the saving name\n",
    "                    saving_name = f\"{target_file_radix}_s{c_ount}_y{chunk_y_coord}_x{chunk_x_coord}.tif\"\n",
    "                    #form the saving directory based on whether sample should be used for train, validation or test and save the results\n",
    "                    if i_f in train_samples:\n",
    "                        raw_full_saving_directory_train = os.path.join(output_train_folder_raw, saving_name)\n",
    "                        label_full_saving_directory_train = os.path.join(output_train_folder_label, saving_name)\n",
    "                        tifffile.imwrite(raw_full_saving_directory_train, chunk_array_raw, photometric='minisblack')\n",
    "                        tifffile.imwrite(label_full_saving_directory_train, chunk_array_label, photometric='minisblack')\n",
    "                    #form the saving directory based on whether sample should be used for train, validation or test and save the results\n",
    "                    elif i_f in validation_samples:\n",
    "                        raw_full_saving_directory_validation = os.path.join(output_validation_folder_raw, saving_name)\n",
    "                        label_full_saving_directory_validation = os.path.join(output_validation_folder_label, saving_name)\n",
    "                        tifffile.imwrite(raw_full_saving_directory_validation, chunk_array_raw, photometric='minisblack')\n",
    "                        tifffile.imwrite(label_full_saving_directory_validation, chunk_array_label, photometric='minisblack')\n",
    "                    #form the saving directory based on whether sample should be used for train, validation or test and save the results\n",
    "                    elif i_f in test_samples:\n",
    "                        raw_full_saving_directory_test = os.path.join(output_test_folder_raw, saving_name)\n",
    "                        label_full_saving_directory_test = os.path.join(output_test_folder_label, saving_name)\n",
    "                        tifffile.imwrite(raw_full_saving_directory_test, chunk_array_raw, photometric='minisblack')\n",
    "                        tifffile.imwrite(label_full_saving_directory_test, chunk_array_label, photometric='minisblack')\n",
    "                    else:\n",
    "                        print(f\"sample {i_f} was neither in the train samples nor in the test samples\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip2_segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
